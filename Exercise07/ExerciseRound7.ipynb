{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This cell is used for creating a button that hides/unhides code cells to quickly look only the results.\n",
    "# Works only with Jupyter Notebooks.\n",
    "\n",
    "import os\n",
    "from IPython.display import HTML\n",
    "\n",
    "HTML('''<script>\n",
    "code_show=true;\n",
    "function code_toggle() {\n",
    "if (code_show){\n",
    "$('div.input').hide();\n",
    "} else {\n",
    "$('div.input').show();\n",
    "}\n",
    "code_show = !code_show\n",
    "}\n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Description:\n",
    "#   Exercise7 notebook.\n",
    "#\n",
    "# Copyright (C) 2018 Santiago Cortes, Juha Ylioinas\n",
    "#\n",
    "# This software is distributed under the GNU General Public \n",
    "# Licence (version 2 or later); please refer to the file \n",
    "# Licence.txt, included with the software, for details.\n",
    "\n",
    "# Preparations\n",
    "import numpy as np\n",
    "\n",
    "# Select data directory\n",
    "if os.path.isdir('/coursedata'):\n",
    "    # JupyterHub\n",
    "    course_data_dir = '/coursedata'\n",
    "elif os.path.isdir('../../../coursedata'):\n",
    "    # Local installation\n",
    "    course_data_dir = '../../../coursedata'\n",
    "else:\n",
    "    # Docker\n",
    "    course_data_dir = '/home/jovyan/work/coursedata/'\n",
    "\n",
    "print('The data directory is %s' % course_data_dir)\n",
    "data_dir = os.path.join(course_data_dir, 'exercise-07-data')\n",
    "print('Data stored in %s' % data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS-E4850 Computer Vision Exercise Round 7\n",
    "The problems should be solved before the exercise session and solutions returned via\n",
    "MyCourses. <br><br> For this exercise round, upload this notebook(pdf and .ipynb versions) containing your source codes (for Exercise 1) and your answer to the question of Exercise2, and all the answers to the questions of Exercise 3 (VGG practical), see part[1-3].ipynb. Note that it's not necessary to upload part1.ipynb, part2.ipynb or part3.ipynb, because all of the necessary questions related to them are contained in this notebook and you're not expected to do any coding in Exercises 2 and 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 - Comparing  bags-of-words  with  tf-idf  weighting\n",
    "Assume  that  we  have  an  indexed  collection  of  documents  containing  the  five  terms  of the following table where the second row indicates the percentage of documents in which each term appears.<br>\n",
    "\n",
    "| term | cat | dog |mammals | mouse | pet |\n",
    "| --- | :---: | :---: | :---: | :---: | :---: |\n",
    "| **% of documents** | 5 | 20 | 2 | 10 | 60 |\n",
    "\n",
    "Now, given the query $Q=\\{mouse, cat, pet, mammals\\}$, compute the similarity between $Q$ and the following example documents $D1$, $D2$, $D3$, by using the cosine similarity measure and tf-idf weights (i.e. term frequency - inverse document frequency) for the bag-of-words histogram representations of the documents and the query.\n",
    "\n",
    "-  $D1$ = Cat is a pet, dog is a pet, and mouse may be a pet too.\n",
    "-  $D2$ = Cat, dog and mouse are all mammals.\n",
    "-  $D3$ = Cat and dog get along well, but cat may eat a mouse.\n",
    "\n",
    "Ignore other words except the five terms, which are listed in the table above. You may proceed with the following steps:\n",
    "\n",
    "a) Compute and report the inverse document frequency (idf) for each of the five terms. Use the logarithm with base 2.  (idf is the logarithm term on slide 69 of Lecture 6 where values $n_i/N$ are given in the table above.)<br>\n",
    "b) Compute the term frequencies for the query and each document. <br>\n",
    "c) Form the tf-idf weighted word occurrence histograms for the query and documents. <br>\n",
    "d) Evaluate the cosine similarity between the query and each document (i.e.\\ normalized scalar product between the weighted occurrence histograms as shown on slide 45).<br> \n",
    "e) Report the relative ranking of the documents. (You should get similarities 0.95, 0.64, and 0.63, but you need to determine which corresponds to which document.)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Comparing  bags-of-words  with  tf-idf  weighting\n",
    "##--your-code-starts-here--##\n",
    "\n",
    "from typing import List\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def tokenize(text: str) -> List[str]:\n",
    "    # Remove punctuation using regex, keeping words and numbers\n",
    "    cleaned_text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "    # Split the cleaned text into words\n",
    "    tokens = cleaned_text.lower().split()\n",
    "    return tokens\n",
    "\n",
    "# Given terms and document frequencies\n",
    "terms = ['cat', 'dog', 'mammals', 'mouse', 'pet']  \n",
    "document_frequency = {'cat': 0.05, 'dog': 0.20, 'mammals': 0.02, 'mouse': 0.1, 'pet': 0.6}\n",
    "\n",
    "\n",
    "# Example documents\n",
    "query = [\"cat\", \"mammals\", \"mouse\", \"pet\"]\n",
    "d1 = \"Cat is a pet, dog is a pet, and mouse may be a pet too.\"\n",
    "d2 = \"Cat, dog and mouse are all mammals.\"\n",
    "d3 = \"Cat and dog get along well, but cat may eat a mouse.\"\n",
    "d1 = tokenize(d1)\n",
    "d2 = tokenize(d2)\n",
    "d3 = tokenize(d3)\n",
    "\n",
    "# List of all documents tokenized\n",
    "documents = [d1, d2, d3]\n",
    "\n",
    "# a) Compute idf for each term\n",
    "idf = {term: np.log2(1/document_frequency[term]) for term in terms}\n",
    "\n",
    "# b) Compute term frequency (tf) for each term in each document and query\n",
    "total_corpus = set(d1).union(set(d2)).union(set(d3)).union(set(query))\n",
    "\n",
    "# Initialize dictionaries for word counts for each document\n",
    "word_count_query = dict.fromkeys(total_corpus, 0)\n",
    "word_count_d1 = dict.fromkeys(total_corpus, 0)\n",
    "word_count_d2 = dict.fromkeys(total_corpus, 0)\n",
    "word_count_d3 = dict.fromkeys(total_corpus, 0)\n",
    "\n",
    "# Count word occurrences in each document\n",
    "for word in query:\n",
    "    word_count_query[word] += 1\n",
    "for word in d1:\n",
    "    word_count_d1[word] += 1\n",
    "for word in d2:\n",
    "    word_count_d2[word] += 1\n",
    "for word in d3:\n",
    "    word_count_d3[word] += 1\n",
    "\n",
    "# Filter word counts by the terms of interest\n",
    "word_count_query = {k: v for k, v in word_count_query.items() if k in terms}\n",
    "word_count_d1 = {k: v for k, v in word_count_d1.items() if k in terms}\n",
    "word_count_d2 = {k: v for k, v in word_count_d2.items() if k in terms}\n",
    "word_count_d3 = {k: v for k, v in word_count_d3.items() if k in terms}\n",
    "\n",
    "# Create a DataFrame to display term frequencies\n",
    "freq = pd.DataFrame([word_count_query, word_count_d1, word_count_d2, word_count_d3])\n",
    "print(\"Term Frequency (TF):\")\n",
    "print(freq.T)\n",
    "\n",
    "\n",
    "# c) Form the tf-idf weighted word occurrence histograms for each document\n",
    "\n",
    "# get the total size of each document (for size only matters words in terms)\n",
    "total_size_query = sum(word_count_query.values())\n",
    "total_size_d1 = sum(word_count_d1.values())\n",
    "total_size_d2 = sum(word_count_d2.values())\n",
    "total_size_d3 = sum(word_count_d3.values())\n",
    "\n",
    "tf_idf_query = {term: word_count_query.get(term, 0) * idf.get(term, 0) / total_size_query for term in terms}\n",
    "tf_idf_d1 = {term: word_count_d1.get(term, 0) * idf.get(term, 0) / total_size_d1 for term in terms}\n",
    "tf_idf_d2 = {term: word_count_d2.get(term, 0) * idf.get(term, 0) / total_size_d2 for term in terms}\n",
    "tf_idf_d3 = {term: word_count_d3.get(term, 0) * idf.get(term, 0) / total_size_d3 for term in terms}\n",
    "\n",
    "# Create DataFrames for tf-idf values\n",
    "tf_idf_df = pd.DataFrame([tf_idf_query, tf_idf_d1, tf_idf_d2, tf_idf_d3])\n",
    "print(\"\\nTF-IDF Weighted Values:\")\n",
    "print(tf_idf_df.T)\n",
    "\n",
    "def plot_tf_idf_histogram(tf_idf, doc_number):\n",
    "    terms = list(tf_idf.keys())\n",
    "    values = list(tf_idf.values())\n",
    "    \n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.bar(terms, values, color='skyblue')\n",
    "    plt.xlabel('Terms')\n",
    "    plt.ylabel('TF-IDF Weight')\n",
    "    if doc_number == 0:\n",
    "        plt.title('TF-IDF for Query')\n",
    "    else:\n",
    "        plt.title(f'TF-IDF for Document {doc_number}')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot the histograms for each document\n",
    "plot_tf_idf_histogram(tf_idf_query, 0)\n",
    "plot_tf_idf_histogram(tf_idf_d1, 1)\n",
    "plot_tf_idf_histogram(tf_idf_d2, 2)\n",
    "plot_tf_idf_histogram(tf_idf_d3, 3)\n",
    "\n",
    "# d) Compute the cosine similarity between the documents\n",
    "def cosine_similarity(doc_vector, query_vector):\n",
    "    dot_product = np.dot(doc_vector, query_vector)\n",
    "    norm_doc = np.linalg.norm(doc_vector)\n",
    "    norm_query = np.linalg.norm(query_vector)\n",
    "    if norm_doc == 0 or norm_query == 0:  # Avoid division by zero\n",
    "        return 0.0\n",
    "    return dot_product / (norm_doc * norm_query)\n",
    "    \n",
    "# Convert the TF-IDF dictionaries to vectors for cosine similarity computation\n",
    "def tf_idf_to_vector(tf_idf_dict, terms):\n",
    "    return np.array([tf_idf_dict.get(term, 0) for term in terms])\n",
    "\n",
    "# Convert the query and document TF-IDF values to vectors\n",
    "tf_idf_vector_query = tf_idf_to_vector(tf_idf_query, terms)\n",
    "tf_idf_vector_d1 = tf_idf_to_vector(tf_idf_d1, terms)\n",
    "tf_idf_vector_d2 = tf_idf_to_vector(tf_idf_d2, terms)\n",
    "tf_idf_vector_d3 = tf_idf_to_vector(tf_idf_d3, terms)\n",
    "\n",
    "# Compute cosine similarity between the query and each document\n",
    "similarity_d1 = cosine_similarity(tf_idf_vector_d1, tf_idf_vector_query)\n",
    "similarity_d2 = cosine_similarity(tf_idf_vector_d2, tf_idf_vector_query)\n",
    "similarity_d3 = cosine_similarity(tf_idf_vector_d3, tf_idf_vector_query)\n",
    "\n",
    "# Output the similarity values\n",
    "print(f\"Cosine Similarity (Document 1, Query): {similarity_d1}\")\n",
    "print(f\"Cosine Similarity (Document 2, Query): {similarity_d2}\")\n",
    "print(f\"Cosine Similarity (Document 3, Query): {similarity_d3}\")\n",
    "##--your-code-ends-here--##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 - Precision  and  recall\n",
    "There is a database of 10000 images and a user, who is only interested in images which contain a car. It is known that there are 500 such images in the database. An  automatic image retrieval system retrieves 300 car images and 50 other images from the database. Determine and report the precision and recall of the retrieval  system in this particular case.<br> \n",
    "(Hint: Precision and recall are explained on slide 67 of Lecture 6 and there is a good explanation also in Wikipedia.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type your answer here:\n",
    "Type your answer here:\n",
    "\n",
    "Precision = #relevant_retrieved / #total_retrieved\n",
    "Recall = #relevant_retrieved / #total_relevant\n",
    "\n",
    "Precision=300/350=0.857\n",
    "Recall=300/500=0.6\n",
    "\n",
    "Precision is 85.7%, meaning that 85.7% of the images retrieved by the system were relevant (car images).\n",
    "Recall is 60%, meaning that 60% of all the car images in the database were retrieved by the system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 - VGG practical on object instance recognition\n",
    "See the questions in part[1-3].ipynb and write your answers here.\n",
    "\n",
    "Part1:\n",
    "Stage I.A (two questions)\n",
    "Stage I.B (two questions)\n",
    "Stage I.C (one question)\n",
    "\n",
    "Part2 (one question)\n",
    "\n",
    "Part3:\n",
    "Stage III.A (three questions)\n",
    "Stage III.B (one question)\n",
    "Stage III.C (two questions)\n",
    "\n",
    "Answering questions in part 1 corresponds to one bonus point and parts 2 and 3 together correspond to one additional point. Hence, in total this third task is worth of 2 points, whereas the previous tasks (Exercise 1 and Exercise 2) are both worth of 1 point so that in total this homework round is worth of 4 points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type your answers here: "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
